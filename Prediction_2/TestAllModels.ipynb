{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a86b3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d238157f",
   "metadata": {},
   "outputs": [],
   "source": [
    "games = pd.read_csv('../games.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b923e550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique genres: 16\n",
      "Some unique genres: ['Action', 'Adventure', 'Animation & Modeling', 'Casual', 'Design & Illustration', 'Early Access', 'Free To Play', 'Indie', 'Massively Multiplayer', 'RPG']\n",
      "\n",
      "Full list of unique genres:\n",
      "1. Action\n",
      "2. Adventure\n",
      "3. Animation & Modeling\n",
      "4. Casual\n",
      "5. Design & Illustration\n",
      "6. Early Access\n",
      "7. Free To Play\n",
      "8. Indie\n",
      "9. Massively Multiplayer\n",
      "10. RPG\n",
      "11. Racing\n",
      "12. Simulation\n",
      "13. Sports\n",
      "14. Strategy\n",
      "15. Utilities\n",
      "16. Video Production\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# genre strings into real lists\n",
    "def parse_genres(genre_str):\n",
    "    try:\n",
    "        return ast.literal_eval(genre_str)\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "games['genres_list'] = games['genres'].apply(parse_genres)\n",
    "\n",
    "# find unique genres\n",
    "all_genres = [\n",
    "    genre\n",
    "    for sublist in games['genres_list']\n",
    "    if isinstance(sublist, list)\n",
    "    for genre in sublist\n",
    "]\n",
    "\n",
    "unique_genres = sorted(set(all_genres))\n",
    "print(\"Number of unique genres:\", len(unique_genres))\n",
    "print(\"Some unique genres:\", unique_genres[:10])\n",
    "\n",
    "# full numbered list of genres\n",
    "print(\"\\nFull list of unique genres:\")\n",
    "for i, genre in enumerate(unique_genres, start=1):\n",
    "    print(f\"{i}. {genre}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d85cc3e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro F1 Score: 0.7120410002252759\n",
      "Macro F1 Score: 0.4335677536868626\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "               Action       0.80      0.75      0.77      5987\n",
      "            Adventure       0.73      0.66      0.69      5454\n",
      " Animation & Modeling       0.00      0.00      0.00        17\n",
      "               Casual       0.71      0.60      0.65      5574\n",
      "Design & Illustration       1.00      0.06      0.12        16\n",
      "         Early Access       0.70      0.14      0.23      1408\n",
      "         Free To Play       0.58      0.04      0.08       669\n",
      "                Indie       0.79      0.94      0.86      9860\n",
      "Massively Multiplayer       0.74      0.13      0.23       277\n",
      "                  RPG       0.81      0.48      0.61      2266\n",
      "               Racing       0.89      0.51      0.65       557\n",
      "           Simulation       0.77      0.46      0.58      2804\n",
      "               Sports       0.86      0.39      0.54       657\n",
      "             Strategy       0.82      0.50      0.62      2711\n",
      "            Utilities       1.00      0.19      0.31        43\n",
      "     Video Production       0.00      0.00      0.00        13\n",
      "\n",
      "            micro avg       0.77      0.66      0.71     38313\n",
      "            macro avg       0.70      0.37      0.43     38313\n",
      "         weighted avg       0.77      0.66      0.69     38313\n",
      "          samples avg       0.77      0.70      0.70     38313\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# parse genres\n",
    "import ast\n",
    "\n",
    "def parse_genres(genre_str):\n",
    "    try:\n",
    "        if isinstance(genre_str, list):\n",
    "            return genre_str\n",
    "        return ast.literal_eval(genre_str)\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "games['genres'] = games['genres'].apply(parse_genres)\n",
    "\n",
    "# combine text fields\n",
    "text_columns = ['name', 'short_description', 'about_the_game', 'detailed_description']\n",
    "games['combined_text'] = games[text_columns].fillna('').agg(' '.join, axis=1)\n",
    "\n",
    "# TF-IDF\n",
    "tfidf = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "X = tfidf.fit_transform(games['combined_text'])\n",
    "\n",
    "# multilabelbinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "Y = mlb.fit_transform(games['genres'])\n",
    "\n",
    "# split data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# One-vs-Rest logistic regression\n",
    "model = OneVsRestClassifier(LogisticRegression(max_iter=1000))\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# evaluate\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Micro F1 Score:\", f1_score(Y_test, Y_pred, average='micro'))\n",
    "print(\"Macro F1 Score:\", f1_score(Y_test, Y_pred, average='macro'))\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(Y_test, Y_pred, target_names=mlb.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fbfcc037",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from tensorflow import keras\n",
    "#from keras.models import Model\n",
    "from keras.layers import Dense, Dropout\n",
    "#from keras.optimizers import Adam\n",
    "from keras import Sequential\n",
    "#from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import ast\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0da65b6",
   "metadata": {},
   "source": [
    "### NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f6ae44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "680/680 [==============================] - 3s 4ms/step - loss: 0.2607 - accuracy: 0.3239 - val_loss: 0.2265 - val_accuracy: 0.3614\n",
      "Epoch 2/10\n",
      "680/680 [==============================] - 3s 4ms/step - loss: 0.2170 - accuracy: 0.3905 - val_loss: 0.2218 - val_accuracy: 0.3873\n",
      "Epoch 3/10\n",
      "680/680 [==============================] - 3s 4ms/step - loss: 0.2014 - accuracy: 0.4071 - val_loss: 0.2225 - val_accuracy: 0.4222\n",
      "Epoch 4/10\n",
      "680/680 [==============================] - 3s 4ms/step - loss: 0.1862 - accuracy: 0.4182 - val_loss: 0.2272 - val_accuracy: 0.4099\n",
      "Epoch 5/10\n",
      "680/680 [==============================] - 3s 4ms/step - loss: 0.1679 - accuracy: 0.4315 - val_loss: 0.2341 - val_accuracy: 0.4146\n",
      "Epoch 6/10\n",
      "680/680 [==============================] - 3s 4ms/step - loss: 0.1459 - accuracy: 0.4525 - val_loss: 0.2474 - val_accuracy: 0.4248\n",
      "Epoch 7/10\n",
      "680/680 [==============================] - 3s 4ms/step - loss: 0.1213 - accuracy: 0.4705 - val_loss: 0.2684 - val_accuracy: 0.4330\n",
      "Epoch 8/10\n",
      "680/680 [==============================] - 3s 4ms/step - loss: 0.0981 - accuracy: 0.4822 - val_loss: 0.2950 - val_accuracy: 0.4233\n",
      "Epoch 9/10\n",
      "680/680 [==============================] - 3s 4ms/step - loss: 0.0789 - accuracy: 0.4922 - val_loss: 0.3234 - val_accuracy: 0.3941\n",
      "Epoch 10/10\n",
      "680/680 [==============================] - 3s 4ms/step - loss: 0.0649 - accuracy: 0.4906 - val_loss: 0.3574 - val_accuracy: 0.4061\n",
      "425/425 [==============================] - 0s 1ms/step\n",
      "Micro F1: 0.7015938606847698\n",
      "Macro F1: 0.505821287136677\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "               Action       0.75      0.79      0.77      5987\n",
      "            Adventure       0.70      0.67      0.68      5454\n",
      " Animation & Modeling       0.67      0.24      0.35        17\n",
      "               Casual       0.68      0.60      0.64      5574\n",
      "Design & Illustration       0.50      0.19      0.27        16\n",
      "         Early Access       0.41      0.24      0.30      1408\n",
      "         Free To Play       0.37      0.11      0.17       669\n",
      "                Indie       0.80      0.90      0.84      9860\n",
      "Massively Multiplayer       0.62      0.20      0.30       277\n",
      "                  RPG       0.71      0.57      0.63      2266\n",
      "               Racing       0.80      0.59      0.68       557\n",
      "           Simulation       0.62      0.57      0.59      2804\n",
      "               Sports       0.74      0.47      0.58       657\n",
      "             Strategy       0.68      0.58      0.63      2711\n",
      "            Utilities       0.68      0.44      0.54        43\n",
      "     Video Production       0.33      0.08      0.12        13\n",
      "\n",
      "            micro avg       0.72      0.68      0.70     38313\n",
      "            macro avg       0.63      0.45      0.51     38313\n",
      "         weighted avg       0.71      0.68      0.69     38313\n",
      "          samples avg       0.73      0.72      0.69     38313\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# parse genres\n",
    "def parse_genres(genre_str):\n",
    "    try:\n",
    "        if isinstance(genre_str, list):\n",
    "            return genre_str\n",
    "        return ast.literal_eval(genre_str)\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "games['genres'] = games['genres'].apply(parse_genres)\n",
    "\n",
    "# combine text fields\n",
    "text_columns = ['name', 'short_description', 'about_the_game', 'detailed_description']\n",
    "games['combined_text'] = games[text_columns].fillna('').agg(' '.join, axis=1)\n",
    "\n",
    "# TF-IDF\n",
    "tfidf = TfidfVectorizer(max_features=3000, stop_words='english')\n",
    "X = tfidf.fit_transform(games['combined_text']).toarray()\n",
    "\n",
    "# multilabelbinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "Y = mlb.fit_transform(games['genres'])\n",
    "\n",
    "# split data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# neural network\n",
    "model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.3),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(Y_train.shape[1], activation='sigmoid')  # sigmoid = multi-label output\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# =train\n",
    "history = model.fit(\n",
    "    X_train, Y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=10,\n",
    "    batch_size=64,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# analysis\n",
    "Y_pred_probs = model.predict(X_test)\n",
    "Y_pred = (Y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "print(\"Micro F1:\", f1_score(Y_test, Y_pred, average='micro'))\n",
    "print(\"Macro F1:\", f1_score(Y_test, Y_pred, average='macro'))\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(Y_test, Y_pred, target_names=mlb.classes_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c03728",
   "metadata": {},
   "source": [
    "### MODEL - SVM - CURRENT BEST MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ab5014f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Micro F1: 0.7085465675679444\n",
      "SVM Macro F1: 0.5321544780828762\n",
      "\n",
      "SVM Classification Report:\n",
      "\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "               Action       0.79      0.75      0.77      5987\n",
      "            Adventure       0.72      0.66      0.69      5454\n",
      " Animation & Modeling       0.78      0.41      0.54        17\n",
      "               Casual       0.69      0.60      0.64      5574\n",
      "Design & Illustration       0.60      0.19      0.29        16\n",
      "         Early Access       0.67      0.15      0.24      1408\n",
      "         Free To Play       0.54      0.04      0.08       669\n",
      "                Indie       0.79      0.93      0.85      9860\n",
      "Massively Multiplayer       0.59      0.19      0.29       277\n",
      "                  RPG       0.79      0.50      0.62      2266\n",
      "               Racing       0.87      0.55      0.67       557\n",
      "           Simulation       0.74      0.48      0.58      2804\n",
      "               Sports       0.81      0.42      0.55       657\n",
      "             Strategy       0.80      0.51      0.63      2711\n",
      "            Utilities       0.86      0.58      0.69        43\n",
      "     Video Production       1.00      0.23      0.38        13\n",
      "\n",
      "            micro avg       0.76      0.66      0.71     38313\n",
      "            macro avg       0.75      0.45      0.53     38313\n",
      "         weighted avg       0.75      0.66      0.69     38313\n",
      "          samples avg       0.76      0.71      0.69     38313\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "svm_model = OneVsRestClassifier(LinearSVC())\n",
    "svm_model.fit(X_train, Y_train)\n",
    "\n",
    "svm_pred = svm_model.predict(X_test)\n",
    "\n",
    "print(\"SVM Micro F1:\", f1_score(Y_test, svm_pred, average='micro'))\n",
    "print(\"SVM Macro F1:\", f1_score(Y_test, svm_pred, average='macro'))\n",
    "print(\"\\nSVM Classification Report:\\n\")\n",
    "print(classification_report(Y_test, svm_pred, target_names=mlb.classes_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56e3808",
   "metadata": {},
   "source": [
    "### MODEL - DECISION TREES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "362df8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree (fast) Micro F1: 0.6548783439399763\n",
      "Decision Tree (fast) Macro F1: 0.412658780156853\n"
     ]
    }
   ],
   "source": [
    "# Less Depth\n",
    "fast_tree = OneVsRestClassifier(\n",
    "    DecisionTreeClassifier(max_depth=10, min_samples_split=10, random_state=42)\n",
    ")\n",
    "fast_tree.fit(X_train, Y_train)\n",
    "\n",
    "fast_tree_pred = fast_tree.predict(X_test)\n",
    "\n",
    "print(\"Decision Tree (fast) Micro F1:\", f1_score(Y_test, fast_tree_pred, average='micro'))\n",
    "print(\"Decision Tree (fast) Macro F1:\", f1_score(Y_test, fast_tree_pred, average='macro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "776ebe40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra Trees Micro F1: 0.5038216336162868\n",
      "Extra Trees Macro F1: 0.1358067857681201\n"
     ]
    }
   ],
   "source": [
    "# More trees\n",
    "extra_trees = OneVsRestClassifier(\n",
    "    ExtraTreesClassifier(n_estimators=100, max_depth=15, n_jobs=-1, random_state=42)\n",
    ")\n",
    "extra_trees.fit(X_train, Y_train)\n",
    "\n",
    "et_pred = extra_trees.predict(X_test)\n",
    "\n",
    "print(\"Extra Trees Micro F1:\", f1_score(Y_test, et_pred, average='micro'))\n",
    "print(\"Extra Trees Macro F1:\", f1_score(Y_test, et_pred, average='macro'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cefb38",
   "metadata": {},
   "source": [
    "### MODEL - RANDOM FORESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d81743fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast Random Forest Micro F1: 0.6195503390550513\n",
      "Fast Random Forest Macro F1: 0.2550785583024753\n"
     ]
    }
   ],
   "source": [
    "fast_rf = OneVsRestClassifier(\n",
    "    RandomForestClassifier(\n",
    "        n_estimators=100,       # fewer trees (for speed)\n",
    "        max_depth=15,           # limit depth (for speed)\n",
    "        min_samples_split=10,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    ")\n",
    "fast_rf.fit(X_train, Y_train)\n",
    "\n",
    "rf_pred = fast_rf.predict(X_test)\n",
    "\n",
    "print(\"Fast Random Forest Micro F1:\", f1_score(Y_test, rf_pred, average='micro'))\n",
    "print(\"Fast Random Forest Macro F1:\", f1_score(Y_test, rf_pred, average='macro'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
